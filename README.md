# Mon Sim: Evolution Simulator
#### Video Demo:  <https://youtu.be/aRwijFuPdnY>

#### Description:
Mon Sim is an evolution simulation inspired by Pokémon. This application models a complex ecosystem where mons(animals) battle for food and reproduce using inherited and mutated neural networks, traits, and stats. Snapshots of the ecosystem are created during runtime at a rate given from the user which can then be observed through a variety of means.

## Project Overview
The simulation runs a set number of turns where each object in the ecosystem gets to act. There are three types of objects in the ecosystem (mons, plants, remains). Mons use neural networks and moves(actions) to interact with the environment the networks chose which move a Mon makes during that turn and the move interacts with and changes the ecosystem in some way. Plants will always try to grow bigger, regrow, and repopulate whether they can or not depends on the space available within the ecosystem. Remains which are left behind for a set number of turns after a Mon dies just slowly decompose and act as a secondary food source to plants for scavengers and predators.
Some of these turns are stored in a database and are displayed in tables and graphs for the user who can then decide if they want to continue the simulation or restart from the beginning with new parameters.

## File Structure and descriptions

### Backend Python Files
**App.py** The Flask application controller which holds the entire system together. This controller acts as a connection to the SQLite SQLAlchemy database, in-between the flask http routes and to the simulation controller(sim.py). SQLAlchemy defines the Turn class which structures the table in the database, it also handles pickle encoding and decoding which is used to condense all of the class elements of the ecosystem into a large binary. Two of the three http routes are also paired with API endpoints that the Frontend calls. The first `/api/eco` returns the whole ecosystem at one point in time via JSON. This is done by unpickling the ecosystem from a turn saved in the database then type casting each object to an ASCII dictionary. While the second `/api/graph` collects an array of multiple datapoints across all stored turns from the database. The third http route uses the ‘GET’ method to either continue the simulation or restart it using the `continue_sim()` and `cold_open()` functions and therefore linking to the simulation manager `sim.py`. This file also contains several miscellaneous helper functions. 

**Sim.py** Sim.py- Acts as the main manager for the simulation. This script contains two key systems the main loop of the simulation and the initialization functions for the start of a new ecosystem. The main loop iterates over each Obj (Mon, Plant, Remains) in the environment and manages what each does on its “turn”. The Mon choses its Moves (Actions) through one or two of its Neural Networks which manage entity interactions (Reproduction, Combat, etc.) the Plant, and Remains turns and their functions are also integrated in the main loop along with the death, starvation, decomposition and repopulation functions shared by each Obj. The ecosystem initialization functions populate a new ecosystem with semi-randomized Plant and Mon populations to help stabilize a new ecosystems but to also provide some random diversity.

**Classes.py** This script defines the core data structures of the simulation. This includes the base Obj class with its subclasses (Mon, Plant, and Remains) including core class features such as `to_dict()` which are used to change these key class objects to ASCII python Dicts for JSON serialization. This script also includes several Enum classes that serve as the keys in important structural key value pairs for various systems including Stats (Hp, Attack, Defense, etc.), Moves (Run, Attack, Mate, Search Plant, etc.), Neuron Functions (Add, Sub, etc.), Neuron Inputs (Other Hp, Self-energy, etc.), Elements(Fire, Water, Plant, etc.) and Traits(Carnivore, Herbivore). The Neuron, and Neural Network class data structures are also defined here.

**Brain.py** This script calculates the output of a Neural Network based on its input. The core function `process_network()` takes a Neural Network and calculates the input values it wants from the environment. The data is then propagated through each layer (input layer, hidden layer, output layer). At the end of the propagation the neuron with the highest value in the output layer represents the Move action that will be used. This is done by processing the data in each Neuron taking the input into the Neuron and modifying it through Neuron class attributes (threshold, neuron activation functions, bias, etc.) all defined in Classes.py. Each Mon has two Neural Networks one is used when the Mon is not in an encounter with another object in the ecosystem and the other is used when the Mon is in an encounter. This “brain” allows the same Mon to interact differently depending both on the external and internal environment.

**Moves.py** Implements and manages all actions that an ecosystem object can execute during its turn. Like the brain there are two sets of moves. The first are basic moves (Rest, Search Plant, Search Mate, etc.) the other ‘encounter’ moves (Mate, Attack, Special Attack, Run). Each move has its own functionality the largest sub-systems in this script are the `mate()` and `combat_move()` subsystems. The `mate()` function handles mating interactions as well as inheritance all values from the two parent objects (Neurons, Traits, Stats, Moves, etc.) as well as random mutation for all those values the function also checks for parental compatibility. The `combat_move()` function handles all attacking and running functions which interact with the stats, elements and move power of each encounter participant.

**Sim_h.py**Contains an assortment of helper functions that are utilized across the script. These are functions like `calculate_size()` which is used to determine how much energy a Mon loses per turn, in calculating the biomass of the ecosystem as well as the potential input value for a neuron in the input layer. Another is the `compare_species()` which represents the genetic distance between animals. It is both used as a prerequisite to mating and as an input value for a Neuron in the input layer Neural Network.

### Frontend Templates
**Index.html** The base template that the other html pages extend from. It sets up the bootstrap framework, jQuery, the sight navigation bar, and the overall page structure. The page uses Jinga2 block syntax for child templates to build from.

**Home.html** Functions as the landing page for the sight and gives a brief description of the project. this template also includes forms that can be submitted via the get method that allows the user to continue a simulation for several steps or restart the simulation giving it a new step interval. These forms are generated dynamically through JavaScript.

**Inspector.html** This script allows the user to examine the ecosystem in detail. The inspector calls `api/eco` for the most recent turn in the database. The user can then scroll through each Mon, Plant, and Remains object and click on it to inspect it. JavaScript builds out each object display when an object is selected, the display shows stat and move tables including JavaScript canvas images for each Neural Network. `api/eco` can be called dynamically by pressing the back and next buttons which allows the user to toggle through each saved turn in the database so that the user can see specific changes over the full range of turns in the database.

**Organizer.html** Provides Macro data visualization of specific data points across time. Though the use of the `/api/graph` the user can select the object (Mon, Plant, Remains), the data type (population, biomass) and color to display and compare singular or multiple data sets in one graph using canvas. The graph automatically scales to the size of the data sets provided and overlays multiple datasets dynamically.

## Design Decisions

### Neural Network Architecture
I decided not to go with fixed neural network structure for my neural network. One reason is because I wanted to see the size and structure of the brain change over time. It is much more obvious to observe that an axon is no longer pointing to the same neuron or that there is one more or one less neuron than there was previously than a bias that is stronger or weaker between two neurons that is always there and does not change. The second reason is for increased diversity among organisms. In this program the more Neurons a Mon has the higher the energy cost of that brain. The core function of this Network is to enhance the simulation and not increase the rate of “learning”. The varying number and changing nature of outputs for example does limit the initial capability of the Mon object by limiting the actions and systems used by it. If a Mon loses the run output neuron for example it can no longer run in any situation. I do this to increase diversity. The expectation is that certain Mons will specialize and develop their own ecological niche since different species cannot be equally good at everything. If they had access to all actions, it would not make for a very diverse simulation. This would make the ecosystem more homogonous overtime instead of diverse which is not the intention.

## Database Storage
I wanted to be able to quickly store the whole ecosystem of class objects without needing to write another type casting function for the database but also reduce the size of the database slightly which lead me to pickle. This made sense because I still wanted to maintain all that data converting it to binary via pickle seemed like the best option. I decided to store the extra data for the graph function (Mon Population, Plant Biomass, etc.) inside the database for runtime reasons instead of unpickling a full ecosystem and iterating through it for one data point I just decided to add each data set to the database along with the ecosystem. However, this does make it harder to implement new data and makes the simulation run longer per turn duo to the additional computation.

## What I Learned
This is the largest project I’ve done to this point, and it is also my first time building a full stack application, utilizing multiple programing languages, working with databases, and working with/within a framework. At least separate from earlier assigned coursework problems. I enjoyed it a lot and I feel like I learned a lot in the process. This is defiantly the type of project that I could continue to iterate and add onto for a long time. Part of that is because I’m learning enough in the process that when I look back to earlier decisions I made, I immediately want to improve or change the older code that I wrote… Which I think is a good sign. I want to change the structure of the database so that I can easily search for more diverse data within populations, I want to let the user mess with more of the global ecosystem parameters, I want to have more 